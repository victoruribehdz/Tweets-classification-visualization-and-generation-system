{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "class LSTM_Classifier:\n",
    "    def __init__(self, data:'pd.Dataframe'=None, max_features:int=200, maxlen:int=200, train:bool=False):\n",
    "        self.corpus = None\n",
    "        self.tokenizer:Tokenizer = Tokenizer()\n",
    "        self.max_features = max_features\n",
    "        self.maxlen = maxlen\n",
    "        self.__process_data__(data)\n",
    "        if train:\n",
    "            self.model = self.__create_model__()\n",
    "        else:\n",
    "            self.model = keras.models.load_model('model.h5')\n",
    "    \n",
    "    def __process_data__(self, data):\n",
    "        def refill(arr:list, zeros):\n",
    "            for i, item in enumerate(arr[::-1]):\n",
    "                if i == len(zeros):\n",
    "                    break\n",
    "                zeros[len(zeros)-i-1] = item\n",
    "\n",
    "            return zeros\n",
    "        data = pd.DataFrame.from_records(data)\n",
    "        # data.rename(columns={'Tweet Text':'text', 'show':'show'})\n",
    "        data = data[['clean_tweets', 'show']]\n",
    "        data = data.dropna(axis=0)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        base = np.zeros(30)\n",
    "\n",
    "        X = [refill(np.asanyarray(x), base) for x in self.vectorize(data['clean_tweets'].values)]\n",
    "\n",
    "        print('selfing: ', type(X))\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, data['show'], train_size=0.8)\n",
    "        \n",
    "        classes = {'got':1, 'rop':0}\n",
    "\n",
    "        # X_train = np.array(X_train)\n",
    "        # X_val = np.array(X_val)\n",
    "\n",
    "        self.data =  {\n",
    "            'x_train':  X_train,\n",
    "            'y_train':  [classes[x] for x in y_train],\n",
    "            'x_val':    X_val,\n",
    "            'y_val':    [classes[x] for x in y_val]\n",
    "        }\n",
    "# np.asarray(self.data[key], dtype=object).astype(np.float32)\n",
    "        self.data = {key:np.asanyarray(self.data[key]) for key in self.data}\n",
    "\n",
    "        print([(type(self.data[x]), len(self.data[x]), self.data[x].shape) for x in self.data])\n",
    "\n",
    "        # print(self.data)\n",
    "\n",
    "    def preprocessing(self, ):\n",
    "        pass\n",
    "\n",
    "    def save(self, ):\n",
    "        self.model.save('model.h5')\n",
    "\n",
    "    def predict(self, text):\n",
    "        #vectorize text\n",
    "\n",
    "        #predict\n",
    "        return self.model.predict([text])\n",
    "\n",
    "    def vectorize(self, data):\n",
    "        tokenizer = self.tokenizer\n",
    "        tokenizer.fit_on_texts(data)\n",
    "        tokens = tokenizer.texts_to_sequences(data)\n",
    "        # print(tokens)\n",
    "        self.corpus = tokens\n",
    "        return tokens\n",
    "\n",
    "    def __create_model__(self, ):\n",
    "        model = Sequential()\n",
    "        total_words = 10\n",
    "        input_len = 10\n",
    "\n",
    "        model.add(Embedding(total_words,150, input_length=input_len))\n",
    "\n",
    "\n",
    "        # inputs = keras.Input(shape=(None, ), dtype='int32')\n",
    "        # x = layers.Embedding(self.max_features, 150)(inputs)\n",
    "        # # Add 2 bidirectional LSTMs\n",
    "        # x = layers.Bidirectional(layers.LSTM(700))(x)\n",
    "        # # x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "        # # Add a classifier\n",
    "        # outputs = layers.Dense(1, activation=\"softmax\")(x)\n",
    "        # model = keras.Model(inputs, outputs)\n",
    "        # model.summary()\n",
    "        # model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "        model.add(LSTM(700))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # ----------Add Output Layer\n",
    "        model.add(Dense(total_words, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "        model.fit(self.data.get('x_train'), self.data.get('y_train'), verbose=5, epochs=20, validation_data=(self.data.get('x_val'), self.data.get('y_val')))\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     import pymongo\n",
    "#     client = pymongo.MongoClient(\"mongodb+srv://tuiter:tuiter@cluster0.avnamve.mongodb.net/?retryWrites=true&w=majority\")\n",
    "#     data = client['TwitterStream']['tweets'].find()\n",
    "#     data = [post for post in data]\n",
    "#     # print(data)\n",
    "#     print('creating the model')\n",
    "#     classifier = LSTM_Classifier(data=data)\n",
    "#     classifier.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import pymongo\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = pymongo.MongoClient(\"mongodb+srv://tuiter:tuiter@cluster0.avnamve.mongodb.net/?retryWrites=true&w=majority\")\n",
    "data = client['TwitterStream']['tweets'].find()\n",
    "data = [post for post in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the ring of power</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tri to avoid ani and all ring of power spoiler...</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okay so ring of power couldnt get the right to...</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the grubbi hobbit in ring of power have crap i...</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i dont realli understand the critic of ring of...</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86995</th>\n",
       "      <td>ive never seen an episod of game of throne any...</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86996</th>\n",
       "      <td>current listen to game of throne soundtrack to...</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86997</th>\n",
       "      <td>game of throne today let get it</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86998</th>\n",
       "      <td>if you arent watch game of throne tonight it p...</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86999</th>\n",
       "      <td>you got it also game of throne premier is next...</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_tweets show\n",
       "0                                      the ring of power  rop\n",
       "1      tri to avoid ani and all ring of power spoiler...  rop\n",
       "2      okay so ring of power couldnt get the right to...  rop\n",
       "3      the grubbi hobbit in ring of power have crap i...  rop\n",
       "4      i dont realli understand the critic of ring of...  rop\n",
       "...                                                  ...  ...\n",
       "86995  ive never seen an episod of game of throne any...  got\n",
       "86996  current listen to game of throne soundtrack to...  got\n",
       "86997                    game of throne today let get it  got\n",
       "86998  if you arent watch game of throne tonight it p...  got\n",
       "86999  you got it also game of throne premier is next...  got\n",
       "\n",
       "[87000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(data)[['clean_tweets', 'show']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more got than rop, let's get equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37000, 50000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['show'] == 'rop']), len(df[df['show'] == 'got'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rop = df[df['show'] == 'rop']\n",
    "df_got = df[df['show'] == 'got'][:37000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>show</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the ring of power</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tri to avoid ani and all ring of power spoiler...</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>okay so ring of power couldnt get the right to...</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the grubbi hobbit in ring of power have crap i...</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i dont realli understand the critic of ring of...</td>\n",
       "      <td>rop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73995</th>\n",
       "      <td>game of throne season episod live stream live ...</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73996</th>\n",
       "      <td>never seen an episod of game of throne in my life</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73997</th>\n",
       "      <td>ive never seen one second of game of throne</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73998</th>\n",
       "      <td>psa if you tri to contact me in ani way dure g...</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73999</th>\n",
       "      <td>rewatch the most metal moment game of throne h...</td>\n",
       "      <td>got</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_tweets show\n",
       "0                                      the ring of power  rop\n",
       "1      tri to avoid ani and all ring of power spoiler...  rop\n",
       "2      okay so ring of power couldnt get the right to...  rop\n",
       "3      the grubbi hobbit in ring of power have crap i...  rop\n",
       "4      i dont realli understand the critic of ring of...  rop\n",
       "...                                                  ...  ...\n",
       "73995  game of throne season episod live stream live ...  got\n",
       "73996  never seen an episod of game of throne in my life  got\n",
       "73997        ive never seen one second of game of throne  got\n",
       "73998  psa if you tri to contact me in ani way dure g...  got\n",
       "73999  rewatch the most metal moment game of throne h...  got\n",
       "\n",
       "[74000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([df_rop,df_got])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 15:42:48.388410: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-12-06 15:42:48.388617: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selfing:  <class 'list'>\n",
      "[(<class 'numpy.ndarray'>, 59200, (59200, 30)), (<class 'numpy.ndarray'>, 59200, (59200,)), (<class 'numpy.ndarray'>, 14800, (14800, 30)), (<class 'numpy.ndarray'>, 14800, (14800,))]\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 15:43:05.931038: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(32, 30)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_ \u001b[39m=\u001b[39m LSTM_Classifier(data\u001b[39m=\u001b[39;49mdata, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn [4], line 20\u001b[0m, in \u001b[0;36mLSTM_Classifier.__init__\u001b[0;34m(self, data, max_features, maxlen, train)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__process_data__(data)\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m train:\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__create_model__()\n\u001b[1;32m     21\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mmodel.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [4], line 108\u001b[0m, in \u001b[0;36mLSTM_Classifier.__create_model__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m model\u001b[39m.\u001b[39madd(Dense(total_words, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m    106\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 108\u001b[0m model\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mx_train\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39my_train\u001b[39;49m\u001b[39m'\u001b[39;49m), verbose\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mx_val\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39my_val\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n\u001b[1;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/p2/4jncb4cn0yx1q4skwg7_9q7m0000gn/T/__autograph_generated_filejcnxy7wy.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/isabelmontalvo/miniconda/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 10), found shape=(32, 30)\n"
     ]
    }
   ],
   "source": [
    "model_ = LSTM_Classifier(data=data, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vec = model_.tokenizer.texts_to_sequences(['tri to avoid ani and all ring of power spoilersfirst impress bc i promis my partner wed watch it togeth when we each other next week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[21284,\n",
       "  11,\n",
       "  684,\n",
       "  17195,\n",
       "  12,\n",
       "  39,\n",
       "  358,\n",
       "  1,\n",
       "  10,\n",
       "  7733,\n",
       "  540,\n",
       "  9,\n",
       "  24,\n",
       "  3521,\n",
       "  10551,\n",
       "  19,\n",
       "  16,\n",
       "  91,\n",
       "  70,\n",
       "  613,\n",
       "  252,\n",
       "  178,\n",
       "  188]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 143ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.57323694]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(text_vec)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x2cc4fb970>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c298a8891c6c57681e79319693c2c68b4b944272c129084f063d59542df9ebf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
